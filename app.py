import streamlit as st
from openai import OpenAI
from PIL import Image
import requests
from io import BytesIO
import datetime
import base64
from typing import Dict, List, Tuple
import time
import random
import json
import uuid
import os
import re
from urllib.parse import urlencode, quote
import gc

# ç‚ºå…è²»æ–¹æ¡ˆè¨­å®šé™åˆ¶
MAX_HISTORY_ITEMS = 15
MAX_FAVORITE_ITEMS = 30
MAX_BATCH_SIZE = 4

# é¢¨æ ¼é è¨­
STYLE_PRESETS = {
    "ç„¡": "", "é›»å½±æ„Ÿ": "cinematic, dramatic lighting, high detail, sharp focus",
    "å‹•æ¼«é¢¨": "anime style, vibrant colors, clean line art", "è³½åšé¾å…‹": "cyberpunk, neon lights, futuristic city, high-tech",
    "æ°´å½©ç•«": "watercolor painting, soft wash, blended colors", "å¥‡å¹»è—è¡“": "fantasy art, epic, detailed, magical",
}

# æ“´å±•çš„åœ–åƒå°ºå¯¸é¸é …
IMAGE_SIZES = {
    "è‡ªå®šç¾©...": "Custom", "1024x1024": "æ­£æ–¹å½¢ (1:1)", "1080x1080": "IG è²¼æ–‡ (1:1)",
    "1080x1350": "IG ç¸±å‘ (4:5)", "1080x1920": "IG Story (9:16)", "1200x630": "FB æ©«å‘ (1.91:1)",
}

def rerun_app():
    if hasattr(st, 'rerun'): st.rerun()
    elif hasattr(st, 'experimental_rerun'): st.experimental_rerun()
    else: st.stop()

st.set_page_config(page_title="FLUX AI (æœ€çµ‚å®Œæ•´ç‰ˆ)", page_icon="ğŸš€", layout="wide")

# API æä¾›å•†
API_PROVIDERS = {
    "Pollinations.ai": {"name": "Pollinations.ai Studio", "base_url_default": "https://image.pollinations.ai", "icon": "ğŸŒ¸"},
    "NavyAI": {"name": "NavyAI", "base_url_default": "https://api.navy/v1", "icon": "âš“"},
    "OpenAI Compatible": {"name": "OpenAI å…¼å®¹ API", "base_url_default": "https://api.openai.com/v1", "icon": "ğŸ¤–"},
}

BASE_FLUX_MODELS = {"flux.1-schnell": {"name": "FLUX.1 Schnell", "icon": "âš¡", "priority": 1}}

# --- æ ¸å¿ƒå‡½æ•¸ ---
def init_session_state():
    if 'api_profiles' not in st.session_state:
        st.session_state.api_profiles = {"é è¨­ Pollinations": {'provider': 'Pollinations.ai', 'api_key': '', 'base_url': 'https://image.pollinations.ai', 'validated': True, 'pollinations_auth_mode': 'å…è²»', 'pollinations_token': '', 'pollinations_referrer': ''}}
    if 'active_profile_name' not in st.session_state or st.session_state.active_profile_name not in st.session_state.api_profiles:
        st.session_state.active_profile_name = list(st.session_state.api_profiles.keys())[0]
    defaults = {'generation_history': [], 'favorite_images': [], 'discovered_models': {}}
    for key, value in defaults.items():
        if key not in st.session_state: st.session_state[key] = value

def get_active_config(): return st.session_state.api_profiles.get(st.session_state.active_profile_name, {})

def auto_discover_models(client, provider, base_url) -> Dict[str, Dict]:
    discovered = {}
    try:
        if provider == "Pollinations.ai":
            response = requests.get(f"{base_url}/models", timeout=10)
            if response.ok:
                models = response.json()
                for model_name in models:
                    discovered[model_name] = {"name": model_name.replace('-', ' ').title(), "icon": "ğŸŒ¸"}
            else: st.warning(f"ç„¡æ³•å¾ Pollinations ç²å–æ¨¡å‹åˆ—è¡¨: HTTP {response.status_code}")
        elif client:
            models = client.models.list().data
            for model in models:
                if 'flux' in model.id.lower():
                    discovered[model.id] = {"name": model.id.replace('-', ' ').replace('_', ' ').title(), "icon": "âš¡"}
    except Exception as e:
        st.error(f"ç™¼ç¾æ¨¡å‹å¤±æ•—: {e}")
    return discovered

def merge_models() -> Dict[str, Dict]:
    provider = get_active_config().get('provider')
    if provider == 'Pollinations.ai':
        # å°æ–¼ Pollinationsï¼Œå¦‚æœæ²’æœ‰ç™¼ç¾æ¨¡å‹ï¼Œå‰‡ä½¿ç”¨é è¨­
        return st.session_state.get('discovered_models') or {"flux": {"name": "Flux (é è¨­)", "icon": "ğŸŒ¸"}}
    else:
        # å°æ–¼å…¶ä»– providerï¼Œåˆä½µåŸºç¤æ¨¡å‹å’Œç™¼ç¾çš„æ¨¡å‹
        return {**BASE_FLUX_MODELS, **st.session_state.get('discovered_models', {})}

def validate_api_key(api_key: str, base_url: str, provider: str) -> Tuple[bool, str]:
    if provider == "Pollinations.ai": return True, "Pollinations.ai ç„¡éœ€é©—è­‰"
    try: OpenAI(api_key=api_key, base_url=base_url).models.list(); return True, "API å¯†é‘°é©—è­‰æˆåŠŸ"
    except Exception as e: return False, f"API é©—è­‰å¤±æ•—: {e}"

def generate_images_with_retry(client, **params) -> Tuple[bool, any]:
    prompt = params.pop("prompt", "")
    if (neg_prompt := params.pop("negative_prompt", None)): prompt += f" --no {neg_prompt}"
    provider = get_active_config().get('provider')
    for attempt in range(3):
        try:
            if provider == "Pollinations.ai":
                width, height = params.get("size", "1024x1024").split('x')
                api_params = {k: v for k, v in {"model": params.get("model"), "width": width, "height": height, "seed": random.randint(0, 1000000), "nologo": params.get("nologo"), "private": params.get("private"), "enhance": params.get("enhance"), "safe": params.get("safe")}.items() if v}
                cfg = get_active_config()
                headers = {}
                auth_mode = cfg.get('pollinations_auth_mode', 'å…è²»')
                if auth_mode == 'ä»¤ç‰Œ' and cfg.get('pollinations_token'): headers['Authorization'] = f"Bearer {cfg['pollinations_token']}"
                elif auth_mode == 'åŸŸå' and cfg.get('pollinations_referrer'): headers['Referer'] = cfg['pollinations_referrer']
                response = requests.get(f"{cfg['base_url']}/prompt/{quote(prompt)}?{urlencode(api_params)}", headers=headers, timeout=120)
                if response.ok: return True, type('MockResponse', (object,), {'data': [type('obj', (object,), {'b64_json': base64.b64encode(response.content).decode()})()]})()
                raise Exception(f"HTTP {response.status_code}: {response.text}")
            else:
                sdk_params = params.copy()
                sdk_params.pop("negative_prompt", None); sdk_params.pop("enhance", None); sdk_params.pop("private", None); sdk_params.pop("nologo", None); sdk_params.pop("safe", None)
                sdk_params["prompt"] = prompt
                sdk_params["response_format"] = "b64_json"
                return True, client.images.generate(**sdk_params)
        except Exception as e:
            if attempt < 2 and ("500" in str(e) or "timeout" in str(e).lower()): time.sleep((attempt + 1) * 2); continue
            return False, str(e)
    return False, "æ‰€æœ‰é‡è©¦å‡å¤±æ•—"

def add_to_history(prompt: str, negative_prompt: str, model: str, images: List[str], metadata: Dict):
    history = st.session_state.generation_history
    history.insert(0, {"id": str(uuid.uuid4()), "timestamp": datetime.datetime.now(), "prompt": prompt, "negative_prompt": negative_prompt, "model": model, "images": images, "metadata": metadata})
    st.session_state.generation_history = history[:MAX_HISTORY_ITEMS]

def display_image_with_actions(b64_json: str, image_id: str, history_item: Dict):
    try:
        img_data = base64.b64decode(b64_json)
        st.image(Image.open(BytesIO(img_data)), use_column_width=True)
        col1, col2, col3 = st.columns(3)
        with col1: st.download_button("ğŸ“¥ ä¸‹è¼‰", img_data, f"flux_{image_id}.png", "image/png", key=f"dl_{image_id}", use_container_width=True)
        with col2:
            is_fav = any(fav['id'] == image_id for fav in st.session_state.favorite_images)
            if st.button("â­" if is_fav else "â˜†", key=f"fav_{image_id}", use_container_width=True, help="æ”¶è—/å–æ¶ˆæ”¶è—"):
                if is_fav: st.session_state.favorite_images = [f for f in st.session_state.favorite_images if f['id'] != image_id]
                else: st.session_state.favorite_images.append({"id": image_id, "image_b64": b64_json, "timestamp": datetime.datetime.now(), "history_item": history_item})
                rerun_app()
        with col3:
            if st.button("ğŸ¨ è®Šé«”", key=f"vary_{image_id}", use_container_width=True, help="ä½¿ç”¨æ­¤æç¤ºç”Ÿæˆè®Šé«”"):
                st.session_state.update({'vary_prompt': history_item['prompt'], 'vary_negative_prompt': history_item.get('negative_prompt', ''), 'vary_model': history_item['model']})
                rerun_app()
    except Exception as e: st.error(f"åœ–åƒé¡¯ç¤ºéŒ¯èª¤: {e}")

def init_api_client():
    cfg = get_active_config()
    if cfg.get('api_key') and cfg.get('provider') != "Pollinations.ai":
        try: return OpenAI(api_key=cfg['api_key'], base_url=cfg['base_url'])
        except Exception: return None
    return None

def show_api_settings():
    st.subheader("âš™ï¸ API å­˜æª”ç®¡ç†")
    profile_names = list(st.session_state.api_profiles.keys())
    active_profile_name = st.selectbox("æ´»å‹•å­˜æª”", profile_names, index=profile_names.index(st.session_state.active_profile_name) if st.session_state.active_profile_name in profile_names else 0)
    
    if active_profile_name != st.session_state.active_profile_name:
        st.session_state.active_profile_name = active_profile_name
        st.session_state.discovered_models = {} # åˆ‡æ›å­˜æª”æ™‚æ¸…ç©ºå·²ç™¼ç¾æ¨¡å‹
        rerun_app()

    active_config = get_active_config().copy()
    with st.expander("ğŸ“ ç·¨è¼¯å­˜æª”å…§å®¹", expanded=True):
        provs = list(API_PROVIDERS.keys())
        sel_prov_name = st.selectbox("API æä¾›å•†", provs, index=provs.index(active_config.get('provider', 'Pollinations.ai')), format_func=lambda x: f"{API_PROVIDERS[x]['icon']} {API_PROVIDERS[x]['name']}")
        
        api_key_input, auth_mode, referrer, token = active_config.get('api_key', ''), 'å…è²»', '', ''
        
        if sel_prov_name == "Pollinations.ai":
            auth_mode = st.radio("èªè­‰æ¨¡å¼", ["å…è²»", "åŸŸå", "ä»¤ç‰Œ"], horizontal=True, index=["å…è²»", "åŸŸå", "ä»¤ç‰Œ"].index(active_config.get('pollinations_auth_mode', 'å…è²»')))
            referrer = st.text_input("æ‡‰ç”¨åŸŸå (Referrer)", value=active_config.get('pollinations_referrer', ''), placeholder="ä¾‹å¦‚: my-app.koyeb.app", disabled=(auth_mode != 'åŸŸå'))
            token = st.text_input("API ä»¤ç‰Œ (Token)", value=active_config.get('pollinations_token', ''), type="password", disabled=(auth_mode != 'ä»¤ç‰Œ'))
        else:
            api_key_input = st.text_input("API å¯†é‘°", value=api_key_input, type="password")
        
        base_url_input = st.text_input("API ç«¯é» URL", value=active_config.get('base_url', API_PROVIDERS[sel_prov_name]['base_url_default']))

    profile_name_input = st.text_input("å­˜æª”åç¨±", value=active_profile_name)
    if st.button("ğŸ’¾ ä¿å­˜/æ›´æ–°å­˜æª”", type="primary"):
        new_config = {'provider': sel_prov_name, 'api_key': api_key_input, 'base_url': base_url_input, 'pollinations_auth_mode': auth_mode, 'pollinations_referrer': referrer, 'pollinations_token': token}
        is_valid, msg = validate_api_key(new_config['api_key'], new_config['base_url'], new_config['provider'])
        new_config['validated'] = is_valid
        
        if profile_name_input != active_profile_name and active_profile_name in st.session_state.api_profiles:
            del st.session_state.api_profiles[active_profile_name]

        st.session_state.api_profiles[profile_name_input] = new_config
        st.session_state.active_profile_name = profile_name_input
        st.session_state.discovered_models = {} # ä¿å­˜å¾Œæ¸…ç©º
        st.success(f"å­˜æª” '{profile_name_input}' å·²ä¿å­˜ã€‚é©—è­‰: {'æˆåŠŸ' if is_valid else 'å¤±æ•—'}")
        time.sleep(1); rerun_app()

init_session_state()
client = init_api_client()
cfg = get_active_config()
api_configured = cfg.get('validated', False)

# --- å´é‚Šæ¬„ ---
with st.sidebar:
    show_api_settings()
    st.markdown("---")
    if api_configured:
        st.success(f"ğŸŸ¢ æ´»å‹•å­˜æª”: '{st.session_state.active_profile_name}'")
        # å°æ–¼ OpenAI å…¼å®¹çš„ APIï¼Œclient å¿…é ˆå­˜åœ¨
        can_discover = (client is not None) or (cfg.get('provider') == "Pollinations.ai")
        if st.button("ğŸ” ç™¼ç¾æ¨¡å‹", use_container_width=True, disabled=not can_discover):
            with st.spinner("ğŸ” æ­£åœ¨ç™¼ç¾æ¨¡å‹..."):
                discovered = auto_discover_models(client, cfg['provider'], cfg['base_url'])
                st.session_state.discovered_models = discovered
                st.success(f"ç™¼ç¾ {len(discovered)} å€‹æ¨¡å‹ï¼") if discovered else st.warning("æœªç™¼ç¾ä»»ä½•æ¨¡å‹ã€‚")
                time.sleep(1); rerun_app()
    else: st.error(f"ğŸ”´ '{st.session_state.active_profile_name}' æœªé©—è­‰")
    st.markdown("---")
    st.info(f"âš¡ **å…è²»ç‰ˆå„ªåŒ–**\n- æ­·å²: {MAX_HISTORY_ITEMS}\n- æ”¶è—: {MAX_FAVORITE_ITEMS}")

st.title("ğŸš€ FLUX AI (æœ€çµ‚å®Œæ•´ç‰ˆ)")

# --- ä¸»ä»‹é¢ ---
tab1, tab2, tab3 = st.tabs(["ğŸš€ ç”Ÿæˆåœ–åƒ", f"ğŸ“š æ­·å² ({len(st.session_state.generation_history)})", f"â­ æ”¶è— ({len(st.session_state.favorite_images)})"])

with tab1:
    if not api_configured: st.warning("âš ï¸ è«‹åœ¨å´é‚Šæ¬„é¸æ“‡ä¸€å€‹å·²é©—è­‰çš„å­˜æª”ã€‚")
    else:
        all_models = merge_models()
        if not all_models: st.warning("âš ï¸ æœªç™¼ç¾ä»»ä½•æ¨¡å‹ã€‚è«‹é»æ“Šå´é‚Šæ¬„çš„ã€Œç™¼ç¾æ¨¡å‹ã€ã€‚")
        else:
            prompt_default = st.session_state.pop('vary_prompt', '')
            neg_prompt_default = st.session_state.pop('vary_negative_prompt', '')
            model_default_key = st.session_state.pop('vary_model', list(all_models.keys())[0])
            model_default_index = list(all_models.keys()).index(model_default_key) if model_default_key in all_models else 0

            sel_model = st.selectbox("æ¨¡å‹:", list(all_models.keys()), index=model_default_index, format_func=lambda x: f"{all_models.get(x, {}).get('icon', 'ğŸ¤–')} {all_models.get(x, {}).get('name', x)}")
            selected_style = st.selectbox("ğŸ¨ é¢¨æ ¼é è¨­:", list(STYLE_PRESETS.keys()))
            prompt_val = st.text_area("âœï¸ æç¤ºè©:", value=prompt_default, height=100, placeholder="ä¸€éš»è²“åœ¨æ—¥è½ä¸‹é£›ç¿”ï¼Œé›»å½±æ„Ÿï¼Œé«˜å“è³ª")
            negative_prompt_val = st.text_area("ğŸš« è² å‘æç¤ºè©:", value=neg_prompt_default, height=50, placeholder="æ¨¡ç³Š, ç³Ÿç³•çš„è§£å‰–çµæ§‹, æ–‡å­—, æ°´å°")
            
            size_preset = st.selectbox("åœ–åƒå°ºå¯¸", options=list(IMAGE_SIZES.keys()), format_func=lambda x: IMAGE_SIZES[x])
            final_size_str = size_preset
            if size_preset == "è‡ªå®šç¾©...":
                w, h = st.columns(2)
                width = w.slider("å¯¬åº¦", 256, 2048, 1024, 64)
                height = h.slider("é«˜åº¦", 256, 2048, 1024, 64)
                final_size_str = f"{width}x{height}"
            
            enhance, private, nologo, safe = False, False, False, False
            if cfg.get('provider') == "Pollinations.ai":
                with st.expander("ğŸŒ¸ Pollinations.ai é€²éšé¸é …"):
                    enhance, private, nologo, safe = st.checkbox("å¢å¼·æç¤ºè©", True), st.checkbox("ç§å¯†æ¨¡å¼", True), st.checkbox("ç§»é™¤æ¨™èªŒ", True), st.checkbox("å®‰å…¨æ¨¡å¼", False)

            if st.button("ğŸš€ ç”Ÿæˆåœ–åƒ", type="primary", use_container_width=True, disabled=not prompt_val.strip()):
                final_prompt = f"{prompt_val}, {STYLE_PRESETS[selected_style]}" if selected_style != "ç„¡" else prompt_val
                with st.spinner("ğŸ¨ æ­£åœ¨ç”Ÿæˆåœ–åƒ..."):
                    params = {"model": sel_model, "prompt": final_prompt, "negative_prompt": negative_prompt_val, "size": final_size_str, "n": 1, "enhance": enhance, "private": private, "nologo": nologo, "safe": safe}
                    success, result = generate_images_with_retry(client, **params)
                    if success:
                        img_b64s = [img.b64_json for img in result.data]
                        add_to_history(prompt_val, negative_prompt_val, sel_model, img_b64s, {"size": final_size_str, "provider": cfg['provider'], "style": selected_style})
                        st.success(f"âœ¨ æˆåŠŸç”Ÿæˆ {len(img_b64s)} å¼µåœ–åƒï¼")
                        cols = st.columns(min(len(img_b64s), 2))
                        for i, b64_json in enumerate(img_b64s):
                            with cols[i % 2]: display_image_with_actions(b64_json, f"{st.session_state.generation_history[0]['id']}_{i}", st.session_state.generation_history[0])
                        gc.collect()
                    else: st.error(f"âŒ ç”Ÿæˆå¤±æ•—: {result}")

with tab2:
    if not st.session_state.generation_history: st.info("ğŸ“­ å°šç„¡ç”Ÿæˆæ­·å²ã€‚")
    else:
        for item in st.session_state.generation_history:
            with st.expander(f"ğŸ¨ {item['prompt'][:50]}... | {item['timestamp'].strftime('%m-%d %H:%M')}"):
                model_name = merge_models().get(item['model'], {}).get('name', item['model'])
                st.markdown(f"**æç¤ºè©**: {item['prompt']}\n\n**æ¨¡å‹**: {model_name}")
                if item.get('negative_prompt'): st.markdown(f"**è² å‘æç¤ºè©**: {item['negative_prompt']}")
                cols = st.columns(min(len(item['images']), 2))
                for i, b64_json in enumerate(item['images']):
                    with cols[i % 2]: display_image_with_actions(b64_json, f"hist_{item['id']}_{i}", item)

with tab3:
    if not st.session_state.favorite_images: st.info("â­ å°šç„¡æ”¶è—çš„åœ–åƒã€‚")
    else:
        cols = st.columns(3)
        for i, fav in enumerate(sorted(st.session_state.favorite_images, key=lambda x: x['timestamp'], reverse=True)):
            with cols[i % 3]: display_image_with_actions(fav['image_b64'], fav['id'], fav.get('history_item'))

st.markdown("""<div style="text-align: center; color: #888; margin-top: 2rem;"><small>ğŸš€ æœ€çµ‚å®Œæ•´ç‰ˆ | éƒ¨ç½²åœ¨ Koyeb å…è²»å¯¦ä¾‹ ğŸš€</small></div>""", unsafe_allow_html=True)
