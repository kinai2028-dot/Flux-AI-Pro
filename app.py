import streamlit as st
from openai import OpenAI
from PIL import Image
import requests
from io import BytesIO
import datetime
import base64
from typing import Dict, List, Optional, Tuple
import time
import random
import json
import uuid
import os
import re
from urllib.parse import urlencode, quote
import gc  # å¼•å…¥è¨˜æ†¶é«”å›æ”¶æ¨¡çµ„

# å„ªåŒ–ï¼šç‚ºå…è²»æ–¹æ¡ˆè¨­å®šæ›´åš´æ ¼çš„é™åˆ¶
MAX_HISTORY_ITEMS = 15
MAX_FAVORITE_ITEMS = 30

# å…¼å®¹æ€§å‡½æ•¸
def rerun_app():
    """å…¼å®¹ä¸åŒ Streamlit ç‰ˆæœ¬çš„é‡æ–°é‹è¡Œå‡½æ•¸"""
    if hasattr(st, 'rerun'):
        st.rerun()
    elif hasattr(st, 'experimental_rerun'):
        st.experimental_rerun()
    else:
        st.stop()

# è¨­å®šé é¢é…ç½®
st.set_page_config(
    page_title="Flux AI (Free Tier Optimized)",
    page_icon="âš¡",
    layout="wide"
)

# API æä¾›å•†é…ç½®
API_PROVIDERS = {
    "OpenAI Compatible": {
        "name": "OpenAI Compatible API",
        "base_url_default": "https://api.openai.com/v1",
        "key_prefix": "sk-",
        "description": "OpenAI å®˜æ–¹æˆ–å…¼å®¹çš„ API æœå‹™",
        "icon": "ğŸ¤–"
    },
    "Navy": {
        "name": "Navy API",
        "base_url_default": "https://api.navy/v1",
        "key_prefix": "sk-",
        "description": "Navy æä¾›çš„ AI åœ–åƒç”Ÿæˆæœå‹™",
        "icon": "âš“"
    },
    "Pollinations.ai": {
        "name": "Pollinations.ai",
        "base_url_default": "https://image.pollinations.ai",
        "key_prefix": "",
        "description": "æ”¯æ´å…è²»å’Œèªè­‰æ¨¡å¼çš„åœ–åƒç”Ÿæˆ API",
        "icon": "ğŸŒ¸",
        "auth_modes": ["free", "referrer", "token"]
    },
    "Hugging Face": {
        "name": "Hugging Face Inference",
        "base_url_default": "https://api-inference.huggingface.co",
        "key_prefix": "hf_",
        "description": "Hugging Face Inference API",
        "icon": "ğŸ¤—"
    },
    "Custom": {
        "name": "è‡ªå®šç¾© API",
        "base_url_default": "",
        "key_prefix": "",
        "description": "è‡ªå®šç¾©çš„ API ç«¯é»",
        "icon": "ğŸ”§"
    }
}

# åŸºç¤ Flux æ¨¡å‹é…ç½®
BASE_FLUX_MODELS = {
    "flux.1-schnell": {
        "name": "FLUX.1 Schnell",
        "description": "æœ€å¿«çš„ç”Ÿæˆé€Ÿåº¦ï¼Œé–‹æºæ¨¡å‹",
        "icon": "âš¡",
        "type": "å¿«é€Ÿç”Ÿæˆ",
        "priority": 1,
        "source": "base",
        "auth_required": False
    },
    "flux.1-dev": {
        "name": "FLUX.1 Dev",
        "description": "é–‹ç™¼ç‰ˆæœ¬ï¼Œå¹³è¡¡é€Ÿåº¦èˆ‡è³ªé‡",
        "icon": "ğŸ”§",
        "type": "é–‹ç™¼ç‰ˆæœ¬",
        "priority": 2,
        "source": "base",
        "auth_required": False
    }
}

# æ¨¡å‹è‡ªå‹•ç™¼ç¾è¦å‰‡
FLUX_MODEL_PATTERNS = {
    r'flux[\\.\\-]?1[\\.\\-]?schnell': {
        "name_template": "FLUX.1 Schnell", "icon": "âš¡", "type": "å¿«é€Ÿç”Ÿæˆ", "priority_base": 100, "auth_required": False
    },
    r'flux[\\.\\-]?1[\\.\\-]?dev': {
        "name_template": "FLUX.1 Dev", "icon": "ğŸ”§", "type": "é–‹ç™¼ç‰ˆæœ¬", "priority_base": 200, "auth_required": False
    },
    r'flux[\\.\\-]?1[\\.\\-]?pro': {
        "name_template": "FLUX.1 Pro", "icon": "ğŸ‘‘", "type": "å°ˆæ¥­ç‰ˆæœ¬", "priority_base": 300, "auth_required": False
    },
    r'flux[\\.\\-]?1[\\.\\-]?kontext|kontext': {
        "name_template": "FLUX.1 Kontext", "icon": "ğŸ¯", "type": "ä¸Šä¸‹æ–‡ç†è§£", "priority_base": 400, "auth_required": True
    }
}

HF_FLUX_ENDPOINTS = [
    "black-forest-labs/FLUX.1-schnell",
    "black-forest-labs/FLUX.1-dev",
]

def auto_discover_flux_models(client, provider: str, api_key: str, base_url: str) -> Dict[str, Dict]:
    discovered_models = {}
    try:
        if provider == "Pollinations.ai":
            response = requests.get(f"{base_url}/models", timeout=10)
            if response.status_code == 200:
                for model_name in response.json():
                    model_info = analyze_model_name(model_name)
                    model_info.update({'source': 'pollinations', 'type': 'åœ–åƒå°ˆç”¨', 'icon': 'ğŸŒ¸'})
                    discovered_models[model_name] = model_info
        elif provider == "Hugging Face":
            for endpoint in HF_FLUX_ENDPOINTS:
                model_id = endpoint.split('/')[-1]
                model_info = analyze_model_name(model_id, endpoint)
                model_info.update({'source': 'huggingface', 'endpoint': endpoint})
                discovered_models[model_id] = model_info
        else:
            for model in client.models.list().data:
                if 'flux' in model.id.lower() or 'kontext' in model.id.lower():
                    model_info = analyze_model_name(model.id)
                    model_info['source'] = 'api_discovery'
                    discovered_models[model.id] = model_info
        return discovered_models
    except Exception as e:
        st.warning(f"æ¨¡å‹è‡ªå‹•ç™¼ç¾å¤±æ•—: {e}")
        return {}

def analyze_model_name(model_id: str, full_path: str = None) -> Dict:
    model_lower = model_id.lower()
    for pattern, info in FLUX_MODEL_PATTERNS.items():
        if re.search(pattern, model_lower):
            analyzed_info = {
                "name": info["name_template"], "icon": info["icon"], "type": info["type"],
                "description": f"è‡ªå‹•ç™¼ç¾çš„ {info['name_template']} æ¨¡å‹",
                "priority": info["priority_base"] + hash(model_id) % 100,
                "auto_discovered": True, "auth_required": info.get("auth_required", False)
            }
            if full_path:
                analyzed_info["full_path"] = full_path
                if '/' in full_path:
                    analyzed_info["name"] += f" ({full_path.split('/')[0]})"
            return analyzed_info
    return {"name": model_id.replace('-', ' ').replace('_', ' ').title(), "icon": "ğŸ¤–", "type": "è‡ªå‹•ç™¼ç¾", "description": f"è‡ªå‹•ç™¼ç¾çš„æ¨¡å‹: {model_id}", "priority": 999, "auto_discovered": True, "auth_required": 'kontext' in model_lower, "full_path": full_path or model_id}

def merge_models() -> Dict[str, Dict]:
    merged_models = {**BASE_FLUX_MODELS, **st.session_state.get('discovered_models', {})}
    return dict(sorted(merged_models.items(), key=lambda item: item[1].get('priority', 999)))

def validate_api_key(api_key: str, base_url: str, provider: str) -> Tuple[bool, str]:
    try:
        if provider == "Pollinations.ai":
            return (True, "Pollinations.ai é€£æ¥æˆåŠŸ") if requests.get(f"{base_url}/models", timeout=10).status_code == 200 else (False, "é€£æ¥å¤±æ•—")
        elif provider == "Hugging Face":
            headers = {"Authorization": f"Bearer {api_key}"}
            return (True, "Hugging Face API é©—è­‰æˆåŠŸ") if requests.get(f"{base_url}/models/black-forest-labs/FLUX.1-schnell", headers=headers, timeout=10).status_code == 200 else (False, "é©—è­‰å¤±æ•—")
        else:
            OpenAI(api_key=api_key, base_url=base_url).models.list()
            return True, "API å¯†é‘°é©—è­‰æˆåŠŸ"
    except Exception as e:
        return False, f"API é©—è­‰å¤±æ•—: {e}"

def generate_images_with_retry(client, provider: str, api_key: str, base_url: str, **params) -> Tuple[bool, any]:
    for attempt in range(3):
        try:
            if provider == "Pollinations.ai":
                p = {k: v for k, v in {"model": params.get("model"), "width": params.get("size", "1024x1024").split('x')[0], "height": params.get("size", "1024x1024").split('x')[1], "seed": random.randint(0, 1000000), "nologo": "true"}.items() if v is not None}
                headers, cfg = {}, st.session_state.get('api_config', {})
                if (auth_mode := cfg.get('pollinations_auth_mode', 'free')) == 'token' and cfg.get('pollinations_token'):
                    headers['Authorization'] = f"Bearer {cfg['pollinations_token']}"
                elif auth_mode == 'referrer' and cfg.get('pollinations_referrer'):
                    headers['Referer'] = cfg['pollinations_referrer']
                response = requests.get(f"{base_url}/prompt/{quote(params.get('prompt', ''))}?{urlencode(p)}", headers=headers, timeout=120)
                if response.ok: return True, type('MockResponse', (object,), {'data': [type('obj', (object,), {'url': f"data:image/png;base64,{base64.b64encode(response.content).decode()}"})()]})()
                raise Exception(f"HTTP {response.status_code}: {response.text}")
            elif provider == "Hugging Face":
                headers, data = {"Authorization": f"Bearer {api_key}"}, {"inputs": params.get("prompt", "")}
                model_name = params.get("model", "FLUX.1-schnell")
                endpoint_path = merge_models().get(model_name, {}).get('full_path', f"black-forest-labs/{model_name}")
                response = requests.post(f"{base_url}/models/{endpoint_path}", headers=headers, json=data, timeout=60)
                if response.ok: return True, type('MockResponse', (object,), {'data': [type('obj', (object,), {'url': f"data:image/png;base64,{base64.b64encode(response.content).decode()}"})()]})()
                raise Exception(f"HTTP {response.status_code}: {response.text}")
            else:
                return True, client.images.generate(**params)
        except Exception as e:
            if attempt < 2 and ("500" in str(e) or "timeout" in str(e).lower()):
                time.sleep((attempt + 1) * 2)
                continue
            return False, str(e)
    return False, "æ‰€æœ‰é‡è©¦å‡å¤±æ•—"

def init_session_state():
    defaults = {
        'api_config': {'provider': 'Navy', 'api_key': '', 'base_url': 'https://api.navy/v1', 'validated': False, 'pollinations_auth_mode': 'free', 'pollinations_token': '', 'pollinations_referrer': ''},
        'generation_history': [], 'favorite_images': [], 'discovered_models': {}
    }
    for key, value in defaults.items():
        if key not in st.session_state: st.session_state[key] = value

def add_to_history(prompt: str, model: str, images: List[str], metadata: Dict):
    history = st.session_state.generation_history
    history.insert(0, {"id": str(uuid.uuid4()), "timestamp": datetime.datetime.now(), "prompt": prompt, "model": model, "images": images, "metadata": metadata})
    st.session_state.generation_history = history[:MAX_HISTORY_ITEMS]

def display_image_with_actions(image_url: str, image_id: str, history_item: Dict = None):
    try:
        img_data = base64.b64decode(image_url.split(',')[1]) if image_url.startswith('data:image') else requests.get(image_url, timeout=10).content
        img = Image.open(BytesIO(img_data))
        st.image(img, use_column_width=True)
        col1, col2 = st.columns(2)
        with col1:
            st.download_button("ğŸ“¥ ä¸‹è¼‰", img_data, f"flux_{image_id}.png", "image/png", key=f"dl_{image_id}", use_container_width=True)
        with col2:
            is_fav = any(fav['id'] == image_id for fav in st.session_state.favorite_images)
            if st.button("â­ å·²æ”¶è—" if is_fav else "â˜† æ”¶è—", key=f"fav_{image_id}", use_container_width=True):
                if is_fav:
                    st.session_state.favorite_images = [f for f in st.session_state.favorite_images if f['id'] != image_id]
                elif len(st.session_state.favorite_images) < MAX_FAVORITE_ITEMS:
                    st.session_state.favorite_images.append({"id": image_id, "image_url": image_url, "timestamp": datetime.datetime.now(), "history_item": history_item})
                else:
                    st.warning(f"æ”¶è—å¤¾å·²æ»¿ (ä¸Šé™ {MAX_FAVORITE_ITEMS} å¼µ)")
                rerun_app()
    except Exception as e:
        st.error(f"åœ–åƒé¡¯ç¤ºéŒ¯èª¤: {e}")

def init_api_client():
    cfg = st.session_state.api_config
    if cfg.get('provider') not in ["Hugging Face", "Pollinations.ai"] and cfg.get('api_key'):
        try: return OpenAI(api_key=cfg['api_key'], base_url=cfg['base_url'])
        except Exception: return None
    return None

def show_api_settings():
    st.subheader("ğŸ”‘ API è¨­ç½®")
    provs = list(API_PROVIDERS.keys())
    sel_prov = st.selectbox("é¸æ“‡ API æä¾›å•†", provs, index=provs.index(st.session_state.api_config.get('provider', 'Navy')), format_func=lambda x: f"{API_PROVIDERS[x]['icon']} {API_PROVIDERS[x]['name']}")
    prov_info = API_PROVIDERS[sel_prov]
    st.info(f"ğŸ“‹ {prov_info['description']}")
    
    key_req = sel_prov not in ["Pollinations.ai"]
    key_in = st.text_input("API å¯†é‘°", type="password", placeholder=f"è¼¸å…¥ {prov_info['name']} çš„ API å¯†é‘°...") if key_req else "N/A"
    url_in = st.text_input("API ç«¯é» URL", value=prov_info['base_url_default'] if sel_prov != st.session_state.api_config.get('provider') else st.session_state.api_config.get('base_url', prov_info['base_url_default']))
    
    if st.button("ğŸ’¾ ä¿å­˜ä¸¦æ¸¬è©¦", type="primary"):
        final_key = key_in if key_in and key_in != "N/A" else st.session_state.api_config.get('api_key', '')
        if key_req and not final_key: st.error("âŒ è«‹è¼¸å…¥ API å¯†é‘°")
        else:
            with st.spinner("æ­£åœ¨é©—è­‰ä¸¦ä¿å­˜..."):
                is_valid, msg = validate_api_key(final_key, url_in, sel_prov)
                st.session_state.api_config.update({'provider': sel_prov, 'api_key': final_key, 'base_url': url_in, 'validated': is_valid})
                st.session_state.discovered_models = {}
                if is_valid: st.success(f"âœ… {msg}ï¼Œè¨­ç½®å·²ä¿å­˜ã€‚")
                else: st.error(f"âŒ {msg}")
                time.sleep(1)
                rerun_app()

def auto_discover_models():
    cfg = st.session_state.api_config
    if (cfg.get('provider') not in ["Pollinations.ai"]) and not cfg.get('api_key'): st.error("âŒ è«‹å…ˆé…ç½® API å¯†é‘°"); return
    with st.spinner("ğŸ” æ­£åœ¨è‡ªå‹•ç™¼ç¾æ¨¡å‹..."):
        client = init_api_client()
        discovered = auto_discover_flux_models(client, cfg['provider'], cfg['api_key'], cfg['base_url'])
        new_count = len(set(discovered.keys()) - set(st.session_state.discovered_models.keys()) - set(BASE_FLUX_MODELS.keys()))
        st.session_state.discovered_models = discovered
        if new_count > 0: st.success(f"âœ… ç™¼ç¾ {new_count} å€‹æ–°æ¨¡å‹ï¼")
        elif discovered: st.info("â„¹ï¸ å·²åˆ·æ–°æ¨¡å‹åˆ—è¡¨ï¼Œæœªç™¼ç¾æ–°æ¨¡å‹ã€‚")
        else: st.warning("âš ï¸ æœªç™¼ç¾ä»»ä½•å…¼å®¹æ¨¡å‹ã€‚")
        time.sleep(1)
        rerun_app()

init_session_state()
client = init_api_client()
cfg = st.session_state.api_config
api_configured = cfg.get('validated', False)

with st.sidebar:
    show_api_settings()
    st.markdown("---")
    if api_configured:
        st.success(f"ğŸŸ¢ {cfg['provider']} API å·²é…ç½®")
        if st.button("ğŸ” ç™¼ç¾æ¨¡å‹", use_container_width=True): auto_discover_models()
    else:
        st.error("ğŸ”´ API æœªé…ç½®æˆ–æœªé©—è­‰")
    st.markdown("---")
    st.info(f"âš¡ **å…è²»ç‰ˆå„ªåŒ–**\n- æ­·å²è¨˜éŒ„ä¸Šé™: {MAX_HISTORY_ITEMS} æ¢\n- æ”¶è—å¤¾ä¸Šé™: {MAX_FAVORITE_ITEMS} å¼µ")

st.title("ğŸ¨ Flux AI åœ–åƒç”Ÿæˆå™¨ (Free Tier)")

tab1, tab2, tab3 = st.tabs(["ğŸš€ åœ–åƒç”Ÿæˆ", f"ğŸ“š æ­·å² ({len(st.session_state.generation_history)})", f"â­ æ”¶è— ({len(st.session_state.favorite_images)})"])

with tab1:
    if not api_configured:
        st.warning("âš ï¸ è«‹å…ˆåœ¨å´é‚Šæ¬„é…ç½®ä¸¦é©—è­‰ API")
    else:
        all_models = merge_models()
        if not all_models:
            st.warning("âš ï¸ å°šæœªç™¼ç¾ä»»ä½•æ¨¡å‹ï¼Œè«‹é»æ“Šå´é‚Šæ¬„çš„ã€Œç™¼ç¾æ¨¡å‹ã€")
        else:
            model_opts = list(all_models.keys())
            sel_model = st.selectbox("é¸æ“‡æ¨¡å‹:", model_opts, format_func=lambda x: f"{all_models[x].get('icon', 'ğŸ¤–')} {all_models[x].get('name', x)}" + (" ğŸ”" if all_models[x].get('auth_required', False) else ""))
            st.info(f"**{all_models[sel_model].get('name')}**: {all_models[sel_model].get('description', 'N/A')}")
            
            prompt_val = st.text_area("è¼¸å…¥æç¤ºè©:", height=100, placeholder="ä¸€éš»è²“åœ¨æ—¥è½ä¸‹é£›ç¿”ï¼Œé›»å½±æ„Ÿï¼Œé«˜å“è³ª")
            
            size = st.selectbox("åœ–åƒå°ºå¯¸", ["1024x1024", "1152x896", "896x1152", "1344x768", "768x1344"], index=0)
            
            if st.button("ğŸš€ ç”Ÿæˆåœ–åƒ", type="primary", use_container_width=True, disabled=not prompt_val.strip()):
                with st.spinner(f"ğŸ¨ ä½¿ç”¨ {all_models[sel_model].get('name')} ç”Ÿæˆä¸­..."):
                    success, result = generate_images_with_retry(client, cfg['provider'], cfg['api_key'], cfg['base_url'], model=sel_model, prompt=prompt_val, n=1, size=size)
                    if success:
                        img_urls = [img.url for img in result.data]
                        add_to_history(prompt_val, sel_model, img_urls, {"size": size, "provider": cfg['provider']})
                        st.success("âœ¨ åœ–åƒç”ŸæˆæˆåŠŸï¼")
                        display_image_with_actions(img_urls[0], f"{st.session_state.generation_history[0]['id']}_0", st.session_state.generation_history[0])
                        gc.collect() # å„ªåŒ–ï¼šç”Ÿæˆå¾Œç«‹å³å›æ”¶è¨˜æ†¶é«”
                    else:
                        st.error(f"âŒ ç”Ÿæˆå¤±æ•—: {result}")

with tab2:
    if st.session_state.generation_history:
        for item in st.session_state.generation_history:
            with st.expander(f"ğŸ¨ {item['prompt'][:60]}... | {item['timestamp'].strftime('%m-%d %H:%M')}"):
                st.markdown(f"**æç¤ºè©**: {item['prompt']}\n\n**æ¨¡å‹**: {merge_models().get(item['model'], {}).get('name', item['model'])}")
                display_image_with_actions(item['images'][0], f"hist_{item['id']}_0", item)
    else: st.info("ğŸ“­ å°šç„¡ç”Ÿæˆæ­·å²")

with tab3:
    if st.session_state.favorite_images:
        cols = st.columns(3)
        for i, fav in enumerate(sorted(st.session_state.favorite_images, key=lambda x: x['timestamp'], reverse=True)):
            with cols[i % 3]:
                display_image_with_actions(fav['image_url'], fav['id'], fav.get('history_item'))
    else: st.info("â­ å°šç„¡æ”¶è—åœ–åƒ")

st.markdown("""<div style="text-align: center; color: #888; margin-top: 2rem;"><small>âš¡ éƒ¨ç½²åœ¨ Koyeb å…è²»å¯¦ä¾‹ | ç‚ºä½è¨˜æ†¶é«”ç’°å¢ƒå„ªåŒ– âš¡</small></div>""", unsafe_allow_html=True)
